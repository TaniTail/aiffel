{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration03 Classification Examples\n",
    "###### 온라인 코어 2기 박수경"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런에 내장된 데이터셋을 불러와 머신러닝을 통한 분류기 모델을 작성해 봅니다. 각각의 분류 문제에서 다양한 모델을 만들어 보고, 적절한 평가지표를 이용해 모델의 성능을 평가합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습은 머신러닝의 지도학습을 연습하는 과정입니다. 지도학습에는 paired data가 정확이 짝지어져 있는, 정답이 있는 데이터를 이용한다고 이해할 수 있습니다. 특히 카테고리가 정해져 있는 분류 문제는 대표적인 지도학습 문제입니다. 분류 문제를 위하여 Decision Tree 모델을 사용합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Digits  Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 필요한 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n",
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits #사이킷런 내장 데이터셋에서 함수 불러오기\n",
    "\n",
    "digits = load_digits() #데이터 로딩.\n",
    "\n",
    "print(dir(digits))\n",
    "print(type(digits)) # Dictionary 자료형과 유사한 sklearn.utils.Bunch 자료형 \n",
    "digits.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 데이터 이해하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 내장 데이터셋에서 load_digit 함수를 불러옵니다. 사이킷런 데이터셋을 이용하는 기본적인 방법은 다음과 같습니다. 먼저 데이터셋의 데이터를 로딩해 와서 변수에 할당합니다. dir을 이용해 객체의 attribute와 method를 확인할 수 있습니다. keys 메서드로는 테이터셋에 담긴 정보의 종류를 알 수 있습니다.  \n",
    "'feature_names', 'target_names' 라는 속성은 데이터가 담고 있는 각 피처의 이름과 타겟을 확인할 수 있습니다.  \n",
    "**피처와 타겟 네임을 출력해 봅니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits.feature_names)\n",
    "print(digits.target_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 '.data' 속성은 데이터셋의 배열정보를 나타냅니다. 배열 정보를 새로운 변수에 할당합니다. DESCR로 데이터셋의 특성을 볼 수 있습니다. 데이터에 대한 이해를 위해 읽어보면, 이 데이터셋은 손으로 쓴 숫자 이미지를 포함하고 있으며 10개의 클래스는 각 숫자를 나타냄을 알 수 있습니다. 32x32 비트맵의 4x4의 중복되지 않는 블록에 담긴 픽셀의 수가 8x8의 행렬으로 표현되어 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 **피처데이터**는 각 블록에 담긴 픽셀의 수인 64개, **레이블 데이터**는 (0~9까지의 각 숫자인) 10개라고 할 수 있겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data = digits.data\n",
    "digits_data.shape  # (손글씨 이미지의 개수, 이미지 당 Pixel 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1797.0</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303840</td>\n",
       "      <td>5.204786</td>\n",
       "      <td>11.835838</td>\n",
       "      <td>11.848080</td>\n",
       "      <td>5.781859</td>\n",
       "      <td>1.362270</td>\n",
       "      <td>0.129661</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>1.993879</td>\n",
       "      <td>...</td>\n",
       "      <td>3.725097</td>\n",
       "      <td>0.206455</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.279354</td>\n",
       "      <td>5.557596</td>\n",
       "      <td>12.089037</td>\n",
       "      <td>11.809126</td>\n",
       "      <td>6.764051</td>\n",
       "      <td>2.067891</td>\n",
       "      <td>0.364496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907192</td>\n",
       "      <td>4.754826</td>\n",
       "      <td>4.248842</td>\n",
       "      <td>4.287388</td>\n",
       "      <td>5.666418</td>\n",
       "      <td>3.325775</td>\n",
       "      <td>1.037383</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>3.196160</td>\n",
       "      <td>...</td>\n",
       "      <td>4.919406</td>\n",
       "      <td>0.984401</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>0.934302</td>\n",
       "      <td>5.103019</td>\n",
       "      <td>4.374694</td>\n",
       "      <td>4.933947</td>\n",
       "      <td>5.900623</td>\n",
       "      <td>4.090548</td>\n",
       "      <td>1.860122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1            2            3            4   \\\n",
       "count  1797.0  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean      0.0     0.303840     5.204786    11.835838    11.848080   \n",
       "std       0.0     0.907192     4.754826     4.248842     4.287388   \n",
       "min       0.0     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.0     0.000000     1.000000    10.000000    10.000000   \n",
       "50%       0.0     0.000000     4.000000    13.000000    13.000000   \n",
       "75%       0.0     0.000000     9.000000    15.000000    15.000000   \n",
       "max       0.0     8.000000    16.000000    16.000000    16.000000   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  ...   \n",
       "mean      5.781859     1.362270     0.129661     0.005565     1.993879  ...   \n",
       "std       5.666418     3.325775     1.037383     0.094222     3.196160  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
       "max      16.000000    16.000000    15.000000     2.000000    16.000000  ...   \n",
       "\n",
       "                54           55           56           57           58  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean      3.725097     0.206455     0.000556     0.279354     5.557596   \n",
       "std       4.919406     0.984401     0.023590     0.934302     5.103019   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     4.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000    10.000000   \n",
       "max      16.000000    13.000000     1.000000     9.000000    16.000000   \n",
       "\n",
       "                59           60           61           62           63  \n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  \n",
       "mean     12.089037    11.809126     6.764051     2.067891     0.364496  \n",
       "std       4.374694     4.933947     5.900623     4.090548     1.860122  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%      11.000000    10.000000     0.000000     0.000000     0.000000  \n",
       "50%      13.000000    14.000000     6.000000     0.000000     0.000000  \n",
       "75%      16.000000    16.000000    12.000000     2.000000     0.000000  \n",
       "max      16.000000    16.000000    16.000000    16.000000    16.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_digits = pd.DataFrame(digits_data)\n",
    "df_digits.head()\n",
    "df_digits.describe() #피처 0~63까지, 그 속의 픽셀값은 min 0 , max 16임을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data[0] # 각 이미지가 64개의 Pixel로 구성된 것을 확인할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 나타내는 것이 이미지 이므로, 이미지화 해 보려고 합니다.\\\n",
    "맷플롯립의 %matplotlib inline 은 IPython에서 제공하는, rich output(그림, 소리, 애니메이션 등)을 표현하게 해 주는 기능입니다. 이를 통해 웹 브라우저로 직접 볼 수 있습니다.  \n",
    "(참고: https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "# 브라우저에서 바로 그림을 볼 수 있게 해주는 역할\n",
    "\n",
    "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
    "plt.axis('off') #행렬의 이미지표현을 위해 축의 표시를 off해 줍니다.\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 숫자들을 다 이미지로 표현해 봅니다. 한 캔버스에 여러개의 그래프나 도표 등을 표현할 때는 subplot을 이용합니다. (subplot과 subplots는 사용법이 조금 다릅니다. 표현하고자 하는 내용의 수와, 특징에 맞게 적절히 선택해야 합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1) # 10개의 이미지를 2행 5열로 표시\n",
    "    plt.imshow(digits.data[i].reshape(8, 8), cmap='gray') \n",
    "    plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,\n",
       "       2, 3, 4, 5, 6, 7, 8, 9, 0, 9, 5, 5, 6, 5, 0, 9, 8, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_label = digits.target #어떤 숫자를 나타내는지를 예측해야 합니다.\n",
    "print(digits_label.shape)\n",
    "digits_label[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2     3     4     5    6    7    8    9  ...   55   56  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  0.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  0.0  0.0   \n",
       "\n",
       "       57   58    59    60    61   62   63  number  \n",
       "0     0.0  6.0  13.0  10.0   0.0  0.0  0.0       0  \n",
       "1     0.0  0.0  11.0  16.0  10.0  0.0  0.0       1  \n",
       "2     0.0  0.0   3.0  11.0  16.0  9.0  0.0       2  \n",
       "3     0.0  7.0  13.0  13.0   9.0  0.0  0.0       3  \n",
       "4     0.0  0.0   2.0  16.0   4.0  0.0  0.0       4  \n",
       "...   ...  ...   ...   ...   ...  ...  ...     ...  \n",
       "1792  0.0  2.0  14.0  15.0   9.0  0.0  0.0       9  \n",
       "1793  0.0  6.0  16.0  14.0   6.0  0.0  0.0       0  \n",
       "1794  0.0  2.0   9.0  13.0   6.0  0.0  0.0       8  \n",
       "1795  0.0  5.0  12.0  16.0  12.0  0.0  0.0       9  \n",
       "1796  1.0  8.0  12.0  14.0  12.0  1.0  0.0       8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_digits['number'] = digits.target\n",
    "df_digits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
    "                                                    digits_label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1004)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (1437,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 64), (360,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 모델을 통해 학습을 진행하고 결과를 봅니다. 이번 실습에서는 다음과 같은 모델을 활용합니다.  \n",
    "- Decision Tree  \n",
    "- Random Forest  \n",
    "- SVM  \n",
    "- SGD Classifier  \n",
    "- Logistic Regression  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델들은 각각의 하이퍼파라미터를 조정하여 더 높은 성능을 가질 수 있습니다. 각각의 모델 하이퍼파라미터들을 적절하게 맞추어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사결정나무 (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055555555555556"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier( criterion = 'entropy', \n",
    "    max_depth = 8, \n",
    "    min_samples_split = 3,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=1004)\n",
    "model_tree.fit(X_train, y_train) # 의사결정나무 모델로 학습\n",
    "y_pred1 = model_tree.predict(X_test) # 테스트 결과 예측\n",
    "\n",
    "accuracy_tree = accuracy_score(y_test, y_pred1)\n",
    "accuracy_tree # 정확도 출력\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런의 분류 성능평가를 위해 내부적으로 여러가지 지표들이 지원됩니다. 가장 간단하게 accuracy를 사용할 수 있으며 classification_report를 통해 지표들을 확인할 수 있습니다.  \n",
    "결과를 지표로 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96        32\n",
      "           1       0.95      0.97      0.96        37\n",
      "           2       0.92      0.88      0.90        26\n",
      "           3       0.90      0.84      0.87        45\n",
      "           4       0.93      0.82      0.87        33\n",
      "           5       0.91      0.78      0.84        37\n",
      "           6       0.91      1.00      0.95        31\n",
      "           7       0.88      0.96      0.91        45\n",
      "           8       0.92      0.95      0.93        37\n",
      "           9       0.84      0.86      0.85        37\n",
      "\n",
      "    accuracy                           0.91       360\n",
      "   macro avg       0.91      0.91      0.91       360\n",
      "weighted avg       0.91      0.91      0.90       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 평가 지표 중 정확도만으로 그 모델의 성능을 기술할 수는 없습니다. 왜냐하면 정확도는 전체 개수 중 맞은 개수만을 나타내기 때문입니다. confusion matrix는 분류 모델이 얼마나 헷갈리고(confused) 있는지를 함께 보여주는 지표입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤포레스트 (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(n_estimators=130, max_depth=8, random_state=1004)\n",
    "model_rf.fit(X_train, y_train)\n",
    "pred2 = model_rf.predict(X_test)\n",
    "accuracy_score(y_test, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      1.00      0.97        37\n",
      "           2       1.00      1.00      1.00        26\n",
      "           3       0.97      0.87      0.92        45\n",
      "           4       1.00      1.00      1.00        33\n",
      "           5       0.95      0.95      0.95        37\n",
      "           6       0.97      1.00      0.98        31\n",
      "           7       0.94      1.00      0.97        45\n",
      "           8       0.94      0.92      0.93        37\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine은 Support Vector와 Hyperplane을 이용한 선형 분류 모델로, 이진 분류를 할 때 바운더리(결정 경계)와 서포트 벡터 (결정 경계로부터 가까운 데이터), 마진 (서포트벡터와 바운더리의 거리)를 통해 데이터의 특징을 표시할 수 있습니다. 두 클래스가 얼마나 명확하게 구분될 수 있는지 시각적으로도 확인할 수 있습니다. 다중 분류 모델에서도 OvO, OvR 방식을 통해 분류를 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm #Support Vector Machine을 import\n",
    "model_svm = svm.SVC(kernel='rbf', degree= 10 ) \n",
    "print(model_svm._estimator_type) # 이 모델이 어떤 타입인지 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        37\n",
      "           2       0.96      1.00      0.98        26\n",
      "           3       1.00      0.98      0.99        45\n",
      "           4       1.00      1.00      1.00        33\n",
      "           5       1.00      0.95      0.97        37\n",
      "           6       0.97      1.00      0.98        31\n",
      "           7       1.00      1.00      1.00        45\n",
      "           8       1.00      1.00      1.00        37\n",
      "           9       0.97      1.00      0.99        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9916666666666667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm.fit(X_train, y_train) # 훈련\n",
    "y_pred3 = model_svm.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred3)) # 결과 지표를 확인\n",
    "accuracy_score(y_test, y_pred3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD (Stochastic Gradient Descent)는 배치 크기가 1인 경사하강법 알고리즘입니다. 즉, 확률적 경사하강법은 데이터 세트에서 무작위로\n",
    "균일하게 선택한 하나의 데이터 포인트를 이용하여 각 단계의 예측 경사를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
    "sgd_model = SGDClassifier() # 모델 객체 생성\n",
    "\n",
    "print(sgd_model._estimator_type) # 이 모델의 타입을 확인\n",
    "sgd_model.fit(X_train, y_train) # sgd모델로 훈련데이터로 훈련시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.86      1.00      0.92        37\n",
      "           2       1.00      1.00      1.00        26\n",
      "           3       0.98      0.91      0.94        45\n",
      "           4       0.97      0.94      0.95        33\n",
      "           5       0.97      0.92      0.94        37\n",
      "           6       0.97      1.00      0.98        31\n",
      "           7       0.98      0.98      0.98        45\n",
      "           8       0.91      0.86      0.89        37\n",
      "           9       0.95      0.97      0.96        37\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred4 = sgd_model.predict(X_test)# 그 모델로 test데이터를 사용해 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred4)) # 결과 지표를 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression은 가장 널리 알려진 선형 분류 알고리즘. 소프트맥스(softmax) 함수를 사용한 다중 클래스 분류 알고리즘이며, 다중 클래스 분류를 위한 로지스틱 회귀를 소프트맥스 회귀(Softmax Regression)라고도 합니다. 이름은 회귀지만, 실제로는 분류를 수행합니다.\n",
    "다중클래스분류알고리즘이기 때문에 클래스가 0~9, 10개인 숫자분류에도 적합합니다. 하이퍼파라미터 중 solver를 liblinear로 설정하면 작은 데이터에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(solver='liblinear').fit(X_train, y_train) \n",
    "\n",
    "print(logistic_model._estimator_type) # 이 모델의 타입을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.90      0.97      0.94        37\n",
      "           2       1.00      1.00      1.00        26\n",
      "           3       0.98      0.93      0.95        45\n",
      "           4       1.00      0.94      0.97        33\n",
      "           5       0.97      0.95      0.96        37\n",
      "           6       0.97      1.00      0.98        31\n",
      "           7       1.00      0.98      0.99        45\n",
      "           8       0.89      0.92      0.91        37\n",
      "           9       0.97      1.00      0.99        37\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred5 = logistic_model.predict(X_test) \n",
    "\n",
    "print(classification_report(y_test, y_pred5,)) # 결과 지표를 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) 모델을 평가해 보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류 모델을 평가하는 지표로 많이 쓰이는 것은 오차행렬로 계산할 수 있는 precision,recall,f1 score,accuracy,fall-out과 ROC-AUC, Log-Loss, support-confidence-lift 등 입니다.  \n",
    "참고:https://rk1993.tistory.com/entry/%EB%AA%A8%EB%8D%B8-%EC%84%B1%EB%8A%A5-%ED%8F%89%EA%B0%80-%EC%A7%80%ED%91%9C-%ED%9A%8C%EA%B7%80-%EB%AA%A8%EB%8D%B8-%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자의 클래스를 인식하여 분류하는 것은 보안문자 입력, 손글씨 인식으로 전화번호, 우편번호, 생일 등의 데이터 저장 등에 쓰입니다. 따라서 **얼마나 많이 맞췄는가, 얼마나 정확한가**가 함께 중요하다고 생각했습니다.예를 들어 숫자 9를 9라고 인식하는 경우에는 의미가 있지만, 그 이외의 틀린 경우에는 어떤 숫자라고 예측했는지는 중요하지 않기 때문입니다. 따라서 오차행렬을 기반으로 모델의 성능을 평가하기로 했고 그 중에서도 **accuracy를 가장 우선적인 지표**로 생각했습니다.  \n",
    "accuracy를 기준으로 하면 가장 성능이 좋은 모델은 SVM (Support Vector Machine)이었습니다. SVM은 기본적으로 이진 분류 모델이지만 다중 클래스 분류를 할 때 이와 같은 이진 분류 알고리즘 모델을 선택하면, 내부적으로 자동으로 OvR, OvO를 실행하게 됩니다. (참고: https://dongsam-memo.tistory.com/24) 따라서 숫자 분류를 실행하면서 SVM 모델은 내부적으로 OvO (One versus One)의 방법으로 다중 분류를 실행한 것입니다. 정확도는 99%로 산출되었습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wine  Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n",
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine #사이킷런 내장 데이터셋에서 함수 불러오기\n",
    "\n",
    "wine = load_wine() #데이터 로딩.\n",
    "\n",
    "print(dir(wine))\n",
    "print(type(wine)) # Dictionary 자료형과 유사한 sklearn.utils.Bunch 자료형 \n",
    "wine.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 이해하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wine 데이터의 feature들의 이름과 target의 이름, 개수를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(wine.feature_names)\n",
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = wine.data\n",
    "wine_data.shape  # (와인 데이터의 개수, 정보의 개수 (피처 개수))를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517   19.494944   99.741573    2.295112   \n",
       "std      0.811827    1.117146    0.274344    3.339564   14.282484    0.625851   \n",
       "min     11.030000    0.740000    1.360000   10.600000   70.000000    0.980000   \n",
       "25%     12.362500    1.602500    2.210000   17.200000   88.000000    1.742500   \n",
       "50%     13.050000    1.865000    2.360000   19.500000   98.000000    2.355000   \n",
       "75%     13.677500    3.082500    2.557500   21.500000  107.000000    2.800000   \n",
       "max     14.830000    5.800000    3.230000   30.000000  162.000000    3.880000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean     2.029270    0.361854    1.590899    5.058090    0.957449    2.611685   \n",
       "std      0.998859    0.124453    0.572359    2.318286    0.228572    0.709990   \n",
       "min      0.340000    0.130000    0.410000    1.280000    0.480000    1.270000   \n",
       "25%      1.205000    0.270000    1.250000    3.220000    0.782500    1.937500   \n",
       "50%      2.135000    0.340000    1.555000    4.690000    0.965000    2.780000   \n",
       "75%      2.875000    0.437500    1.950000    6.200000    1.120000    3.170000   \n",
       "max      5.080000    0.660000    3.580000   13.000000    1.710000    4.000000   \n",
       "\n",
       "                12  \n",
       "count   178.000000  \n",
       "mean    746.893258  \n",
       "std     314.907474  \n",
       "min     278.000000  \n",
       "25%     500.500000  \n",
       "50%     673.500000  \n",
       "75%     985.000000  \n",
       "max    1680.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine = pd.DataFrame(wine_data)\n",
    "df_wine.head()\n",
    "df_wine.describe() #피처 개수와 기술통계량을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       178 non-null    float64\n",
      " 1   1       178 non-null    float64\n",
      " 2   2       178 non-null    float64\n",
      " 3   3       178 non-null    float64\n",
      " 4   4       178 non-null    float64\n",
      " 5   5       178 non-null    float64\n",
      " 6   6       178 non-null    float64\n",
      " 7   7       178 non-null    float64\n",
      " 8   8       178 non-null    float64\n",
      " 9   9       178 non-null    float64\n",
      " 10  10      178 non-null    float64\n",
      " 11  11      178 non-null    float64\n",
      " 12  12      178 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 18.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_wine.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값이 없는 데이터임을 알 수 있습니다. 또한 위의 기술통계량을 확인하니 전체적으로 표준편차가 적은 피처들이 많았습니다. 이는 작은 범위 내에서 미세한 량에 따라 분류가 나누어지게 됨을 의미합니다. 마지막 피처인 와인의 proline(와인의 아미노산의 일종)은 편차가 큼을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "wine_label = wine.target \n",
    "print(wine_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2     3      4     5     6     7     8      9    10  \\\n",
       "0    14.23  1.71  2.43  15.6  127.0  2.80  3.06  0.28  2.29   5.64  1.04   \n",
       "1    13.20  1.78  2.14  11.2  100.0  2.65  2.76  0.26  1.28   4.38  1.05   \n",
       "2    13.16  2.36  2.67  18.6  101.0  2.80  3.24  0.30  2.81   5.68  1.03   \n",
       "3    14.37  1.95  2.50  16.8  113.0  3.85  3.49  0.24  2.18   7.80  0.86   \n",
       "4    13.24  2.59  2.87  21.0  118.0  2.80  2.69  0.39  1.82   4.32  1.04   \n",
       "..     ...   ...   ...   ...    ...   ...   ...   ...   ...    ...   ...   \n",
       "173  13.71  5.65  2.45  20.5   95.0  1.68  0.61  0.52  1.06   7.70  0.64   \n",
       "174  13.40  3.91  2.48  23.0  102.0  1.80  0.75  0.43  1.41   7.30  0.70   \n",
       "175  13.27  4.28  2.26  20.0  120.0  1.59  0.69  0.43  1.35  10.20  0.59   \n",
       "176  13.17  2.59  2.37  20.0  120.0  1.65  0.68  0.53  1.46   9.30  0.60   \n",
       "177  14.13  4.10  2.74  24.5   96.0  2.05  0.76  0.56  1.35   9.20  0.61   \n",
       "\n",
       "       11      12  class  \n",
       "0    3.92  1065.0      0  \n",
       "1    3.40  1050.0      0  \n",
       "2    3.17  1185.0      0  \n",
       "3    3.45  1480.0      0  \n",
       "4    2.93   735.0      0  \n",
       "..    ...     ...    ...  \n",
       "173  1.74   740.0      2  \n",
       "174  1.56   750.0      2  \n",
       "175  1.56   835.0      2  \n",
       "176  1.62   840.0      2  \n",
       "177  1.60   560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine['class'] = wine.target\n",
    "df_wine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "178개의 데이터 개수와, 0, 1, 2 세 그룹의 클래스를 확인했습니다. 데이터의 양이 작은 편이며 분류 클래스 개수도 적은 편이라고 할 수 있습니다. 가장 편차가 큰 컬럼인 12(proline)의 분포를 히스토그램으로 확인하고 이어서 다른 피처들의 비율도 히스토그램으로 알아봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_wine[12].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13., 24., 14., 12., 12., 32., 28., 25., 15.,  3.]),\n",
       " array([1.27 , 1.543, 1.816, 2.089, 2.362, 2.635, 2.908, 3.181, 3.454,\n",
       "        3.727, 4.   ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(4, 3, constrained_layout=True)\n",
    "axs[0, 0].hist(df_wine[0])\n",
    "axs[0, 1].hist(df_wine[1])\n",
    "axs[0, 2].hist(df_wine[2])\n",
    "axs[1, 0].hist(df_wine[3])\n",
    "axs[1, 1].hist(df_wine[4])\n",
    "axs[1, 2].hist(df_wine[5])\n",
    "axs[2, 0].hist(df_wine[6])\n",
    "axs[2, 1].hist(df_wine[7])\n",
    "axs[2, 2].hist(df_wine[8])\n",
    "axs[3, 0].hist(df_wine[9])\n",
    "axs[3, 1].hist(df_wine[10])\n",
    "axs[3, 2].hist(df_wine[11])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(wine_data,\n",
    "                                                    wine_label,\n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.2)\n",
    "                                                    # random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142, 13), (142,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, y_train2.shape\n",
    "# X_test2.shape, y_test2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사결정나무 (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8611111111111112"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree2 = DecisionTreeClassifier( criterion = 'entropy', \n",
    "    max_depth = 3, \n",
    "    min_samples_split = 2,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=1004)\n",
    "model_tree2.fit(X_train2, y_train2) # 의사결정나무 모델로 학습\n",
    "y_pred1_2 = model_tree2.predict(X_test2) # 테스트 결과 예측\n",
    "\n",
    "accuracy_tree2 = accuracy_score(y_test2, y_pred1_2)\n",
    "accuracy_tree2 # 정확도 출력\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤포레스트 (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.91      0.95        11\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rf2 = RandomForestClassifier(n_estimators=130, max_depth=8, random_state=1004)\n",
    "model_rf2.fit(X_train2, y_train2)\n",
    "pred2_2 = model_rf2.predict(X_test2)\n",
    "accuracy_score(y_test2, pred2_2)\n",
    "print(classification_report(y_test2, pred2_2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89        14\n",
      "           1       0.52      1.00      0.69        11\n",
      "           2       0.50      0.09      0.15        11\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.65      0.65      0.58        36\n",
      "weighted avg       0.67      0.67      0.60        36\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm2 = svm.SVC(degree= 3 )\n",
    "model_svm2.fit(X_train2, y_train2) # 훈련\n",
    "y_pred3_2 = model_svm2.predict(X_test2) # 예측\n",
    "\n",
    "print(classification_report(y_test2, y_pred3_2)) # 결과 지표를 확인\n",
    "accuracy_score(y_test2, y_pred3_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87        14\n",
      "           1       1.00      0.27      0.43        11\n",
      "           2       0.59      0.91      0.71        11\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.80      0.70      0.67        36\n",
      "weighted avg       0.80      0.72      0.69        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model2 = SGDClassifier(alpha=0.5, learning_rate='optimal') # 모델 객체 생성\n",
    "\n",
    "print(sgd_model2._estimator_type) # 이 모델의 타입을 확인\n",
    "sgd_model2.fit(X_train2, y_train2) # sgd모델로 훈련데이터로 훈련시킨다.\n",
    "\n",
    "\n",
    "y_pred4_2 = sgd_model2.predict(X_test2)# 그 모델로 test데이터를 사용해 예측\n",
    "\n",
    "print(classification_report(y_test2, y_pred4_2, zero_division=0)) # 결과 지표를 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD는 Mini-Batch를 사용하므로 대량의 데이터를 빨리 계산하는데는 유리하지만 조금 부정확할 수 있습니다. 이 와인 데이터셋은 크기도 작고 간격이 좁은 여러 피처들이 있으므로 정밀함이 필요하다고 생각했습니다. 따라서 SGD는 오차가 클 수밖에 없고 와인 클래스의 분류에는 어울리지 않는 것 같습니다. (참고 : https://mangkyu.tistory.com/62)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.91      0.91      0.91        11\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model2 = LogisticRegression(max_iter=3000) # 모델 객체 생성\n",
    "\n",
    "print(logistic_model2._estimator_type) # 이 모델의 타입을 확인\n",
    "\n",
    "logistic_model2.fit(X_train2, y_train2) #LogisticRegression모델로 훈련데이터를 가지고 훈련시킨다.\n",
    "y_pred5_2 = logistic_model2.predict(X_test2) # 예측\n",
    "\n",
    "print(classification_report(y_test2, y_pred5_2,)) # 결과 지표를 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOTAL NO. of ITERATIONS REACHED LIMIT 은 데이터 분석을 마치기 전에 반복횟수의 한계에 도달했음을 의미합니다. 이럴 경우 max_iter을 증가시켜 줄 필요가 있습니다. 적은 반복횟수로 충분히 수행할 수 있도록 하고 싶다면 데이터를 정규화 한 후 예측하는 것도 좋은 방법이라고 합니다. (참고: https://stackoverflow.com/questions/67604304/total-no-of-iterations-reached-limit-in-scikit-learn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) 모델을 평가해 보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀 모델을 이용한 다중분류는 특히 데이터의 개수가 작을 때 유리한 것 같습니다. 가장 우수한 성능을 보여 채택되었습니다. 와인의 클래스 분류는 미량 성분들의 함류량과 많이 관계가 있음을 알 수 있었습니다. 피처 중 한두개가 유난히 범위가 클 때 정규화를 거쳐 모델에 더 잘 맞는 데이터로 전처리할 수 있음을 알게 되었습니다. 이러한 전처리 방법이 로지스틱 회귀 모델과도 잘 어울린다고 생각했습니다. 이번 분류에서 accuracy는 핵심적인 지표가 아니라고 생각했습니다. 왜냐하면 실제로 데이터의 클래스는 총 3개뿐이며, 데이터 탐색 과정의 히스토그램을 바탕으로 클래스가 고루고루 있음을 알 수 있었기 때문입니다. 이 경우 세 개의 클래스 중 무조건 하나로만 판단하는 모델이 있더라도 제법 맞출 수 있을 것입니다.  \n",
    "제가 중요하다고 생각하는 지표는 f1 스코어였습니다. 정밀도와 재현율을 동시에 고려한 지표이기 때문입니다. 실제로 예측한 클래스가 얼마나 들어맞는지, 정확히 예측한 것들의 비율이 얼마나 되는지를 함께 볼 수 있어서입니다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Breast Cancer  Diagnoses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 필요한 모듈 import하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 분류에서 사용하였던 pandas, numpy, matplotlib, sklearn을 그대로 사용합니다.classification_report또한 꼭 필요한 모듈이며 그에 더해 오차 행렬을 더 자세히 살펴보고 싶으므로 confusion matrix 모듈을 import합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'data_module', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n",
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_b = load_breast_cancer()\n",
    "\n",
    "print(dir(cancer_b))\n",
    "print(type(cancer_b)) #자료형 확인 \n",
    "cancer_b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(cancer_b.feature_names)\n",
    "print(cancer_b.target_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30개의 피처들을 통해 알아내어야 할 target은 종양이 악성인지(malignant), 양성인지(benign) 입니다. **피처와 타겟의 이름을 출력**해 보고 나서 이진분류에 어울리는 모델을 생각해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer_b.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_b_data = cancer_b.data\n",
    "cancer_b_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2            3           4   \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
       "\n",
       "               5           6           7           8           9   ...  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  ...   \n",
       "mean     0.104341    0.088799    0.048919    0.181162    0.062798  ...   \n",
       "std      0.052813    0.079720    0.038803    0.027414    0.007060  ...   \n",
       "min      0.019380    0.000000    0.000000    0.106000    0.049960  ...   \n",
       "25%      0.064920    0.029560    0.020310    0.161900    0.057700  ...   \n",
       "50%      0.092630    0.061540    0.033500    0.179200    0.061540  ...   \n",
       "75%      0.130400    0.130700    0.074000    0.195700    0.066120  ...   \n",
       "max      0.345400    0.426800    0.201200    0.304000    0.097440  ...   \n",
       "\n",
       "               20          21          22           23          24  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               25          26          27          28          29  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancer_b = pd.DataFrame(cancer_b_data)\n",
    "df_cancer_b.head()\n",
    "df_cancer_b.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "       3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "       8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "       3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "       1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_b_data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 불러 온 후 특징을 살핍니다. 특별히 표준편차가 큰 피처들이 있으므로 정규화를 해서 예측하는 것도 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러 선택\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# df_cancer_b = scaler.fit_transform(df_cancer_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_b_corr = df_cancer_b\n",
    "df_cancer_b_corr['diagnosis'] = cancer_b.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>-0.730029</td>\n",
       "      <td>-0.415185</td>\n",
       "      <td>-0.742636</td>\n",
       "      <td>-0.708984</td>\n",
       "      <td>-0.35856</td>\n",
       "      <td>-0.596534</td>\n",
       "      <td>-0.69636</td>\n",
       "      <td>-0.776614</td>\n",
       "      <td>-0.330499</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.456903</td>\n",
       "      <td>-0.782914</td>\n",
       "      <td>-0.733825</td>\n",
       "      <td>-0.421465</td>\n",
       "      <td>-0.590998</td>\n",
       "      <td>-0.65961</td>\n",
       "      <td>-0.793566</td>\n",
       "      <td>-0.416294</td>\n",
       "      <td>-0.323872</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3        4         5        6  \\\n",
       "diagnosis -0.730029 -0.415185 -0.742636 -0.708984 -0.35856 -0.596534 -0.69636   \n",
       "\n",
       "                  7         8         9  ...        21        22        23  \\\n",
       "diagnosis -0.776614 -0.330499  0.012838  ... -0.456903 -0.782914 -0.733825   \n",
       "\n",
       "                 24        25       26        27        28        29  \\\n",
       "diagnosis -0.421465 -0.590998 -0.65961 -0.793566 -0.416294 -0.323872   \n",
       "\n",
       "           diagnosis  \n",
       "diagnosis        1.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmap = df_cancer_b.corr(method='pearson')\n",
    "plt.matshow(hmap)\n",
    "plt.colorbar(shrink=0.8, aspect=10)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "df_cancer_b_corr.corr().tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 피처와 진단결과의 상관관계를 확인했습니다. 9, 11, 14, 18, 19번째 피처는 상관계수가 0에 매우 가까움을 확인했습니다.\n",
    "때로는 지나치게 많은 컬럼이 오버피팅을 발생시키기도 하므로 drop하기로 결정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_b_data = np.delete(cancer_b_data, 9 , axis = 1)\n",
    "cancer_b_data = np.delete(cancer_b_data, 11 , axis = 1)\n",
    "cancer_b_data = np.delete(cancer_b_data, 14 , axis = 1)\n",
    "cancer_b_data = np.delete(cancer_b_data, 18 , axis = 1)\n",
    "cancer_b_data = np.delete(cancer_b_data, 19 , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>-0.730029</td>\n",
       "      <td>-0.415185</td>\n",
       "      <td>-0.742636</td>\n",
       "      <td>-0.708984</td>\n",
       "      <td>-0.35856</td>\n",
       "      <td>-0.596534</td>\n",
       "      <td>-0.69636</td>\n",
       "      <td>-0.776614</td>\n",
       "      <td>-0.330499</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.456903</td>\n",
       "      <td>-0.782914</td>\n",
       "      <td>-0.733825</td>\n",
       "      <td>-0.421465</td>\n",
       "      <td>-0.590998</td>\n",
       "      <td>-0.65961</td>\n",
       "      <td>-0.793566</td>\n",
       "      <td>-0.416294</td>\n",
       "      <td>-0.323872</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3        4         5        6  \\\n",
       "diagnosis -0.730029 -0.415185 -0.742636 -0.708984 -0.35856 -0.596534 -0.69636   \n",
       "\n",
       "                  7         8         9  ...        21        22        23  \\\n",
       "diagnosis -0.776614 -0.330499  0.012838  ... -0.456903 -0.782914 -0.733825   \n",
       "\n",
       "                 24        25       26        27        28        29  \\\n",
       "diagnosis -0.421465 -0.590998 -0.65961 -0.793566 -0.416294 -0.323872   \n",
       "\n",
       "           diagnosis  \n",
       "diagnosis        1.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancer_b_corr = df_cancer_b\n",
    "df_cancer_b_corr['diagnosis'] = cancer_b.target\n",
    "df_cancer_b_corr.corr().tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "cancer_b_label = cancer_b.target \n",
    "print(cancer_b_label.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) train, test 데이터 분리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 전처리된 데이터를 학습할 데이터와 검증할 데이터로 나누겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(cancer_b_data,\n",
    "                                                    cancer_b_label,\n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 25), (455,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3.shape, y_train3.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사결정나무 (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9122807017543859"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree3 = DecisionTreeClassifier( criterion = 'entropy', \n",
    "    max_depth = 3, \n",
    "    min_samples_split = 2,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=1004)\n",
    "model_tree3.fit(X_train3, y_train3) # 의사결정나무 모델로 학습\n",
    "y_pred1_3 = model_tree3.predict(X_test3) # 테스트 결과 예측\n",
    "\n",
    "accuracy_tree3 = accuracy_score(y_test3, y_pred1_3)\n",
    "accuracy_tree3 # 정확도 출력\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤포레스트 (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92        51\n",
      "           1       0.91      0.97      0.94        63\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.93      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rf3 = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=1004)\n",
    "model_rf3.fit(X_train3, y_train3)\n",
    "pred2_3 = model_rf3.predict(X_test3)\n",
    "accuracy_score(y_test3, pred2_3)\n",
    "print(classification_report(y_test3, pred2_3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91        51\n",
      "           1       0.89      1.00      0.94        63\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.94      0.93      0.93       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm3 = svm.SVC( C=1000, kernel='linear')\n",
    "model_svm3.fit(X_train3, y_train3) # 훈련\n",
    "y_pred3_3= model_svm3.predict(X_test3) # 예측\n",
    "\n",
    "print(classification_report(y_test3, y_pred3_3)) # 결과 지표를 확인\n",
    "accuracy_score(y_test3, y_pred3_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.96      0.75        51\n",
      "           1       0.94      0.51      0.66        63\n",
      "\n",
      "    accuracy                           0.71       114\n",
      "   macro avg       0.78      0.73      0.70       114\n",
      "weighted avg       0.79      0.71      0.70       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model3 = SGDClassifier(alpha=0.12) # 모델 객체 생성\n",
    "\n",
    "print(sgd_model3._estimator_type) # 이 모델의 타입을 확인\n",
    "sgd_model3.fit(X_train3, y_train3) # sgd모델로 훈련데이터로 훈련시킨다.\n",
    "\n",
    "\n",
    "y_pred4_3 = sgd_model3.predict(X_test3)# 그 모델로 test데이터를 사용해 예측\n",
    "\n",
    "print(classification_report(y_test3, y_pred4_3)) # 결과 지표를 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92        51\n",
      "           1       0.90      0.98      0.94        63\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model3 = LogisticRegression(max_iter=4000) # 모델 객체 생성\n",
    "\n",
    "print(logistic_model3._estimator_type) # 이 모델의 타입을 확인\n",
    "\n",
    "logistic_model3.fit(X_train3, y_train3) #LogisticRegression모델로 훈련데이터를 가지고 훈련시킨다.\n",
    "y_pred5_3 = logistic_model3.predict(X_test3) # 예측\n",
    "\n",
    "print(classification_report(y_test3, y_pred5_3,)) # 결과 지표를 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) 모델을 평가해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  9]\n",
      " [ 1 62]]\n",
      "==============================================\n",
      "[[45  6]\n",
      " [ 2 61]]\n",
      "==============================================\n",
      "[[43  8]\n",
      " [ 0 63]]\n",
      "==============================================\n",
      "[[49  2]\n",
      " [31 32]]\n",
      "==============================================\n",
      "[[44  7]\n",
      " [ 1 62]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test3, y_pred1_3))\n",
    "print('==============================================')\n",
    "print(confusion_matrix(y_test3, pred2_3))\n",
    "print('==============================================')\n",
    "print(confusion_matrix(y_test3, y_pred3_3))\n",
    "print('==============================================')\n",
    "print(confusion_matrix(y_test3, y_pred4_3))\n",
    "print('==============================================')\n",
    "print(confusion_matrix(y_test3, y_pred5_3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "암 진단에서 핵심적인 것은 첫번째로 recall이라고 생각했습니다. 실제 악성세포를 가지고 있는 사람들 중에 실제로 얼마나 악성으로 진단을 받았는지에 대한 지표이기 때문입니다. 혹여 잘못 진단을 해 암이 아닌 사람도 암으로 진단하였다면 재검사를 거쳐서 알 수 있겠지만, 암이었음에도 진단하지 못한다면 큰일이기 때문입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "안타깝게도 제 모델은 recall 지표가 전체적으로 낮은 점수를 가리킵니다. 오차행렬을 확인하여 그나마 나은 스코어를 보이는 랜덤포레스트를 선택하겠습니다. 데이터 전처리 과정에서 합리적이지 못한 부분이 있었다고 생각되어 회고에 기록하겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Discussion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM 모델은 원래 이중 분류 모델으로 소개되었습니다. 하지만 OvO, OvR 방식과 차원축소등으로 다중 분류모델로서의 기능도 충분히 할 수 있음을 알게 되었습니다. 클래스가 두개인 경우, 혹은 피처가 두개인 경우는 PCA와 mlxtend 라이브러리를 통해서 쉽게 시각화 할 수 있었지만 MNIST 분류는 피처가 64개나 되고 클래스도 10개라서 어려웠습니다. 2차원의 평면에 분류 결과를 표현할 수 없어서 아쉬웠고 꼭 시도해보고 싶습니다.(SVM 모델의 시각화를 통해 분류된 데이터의 정확도를 더 쉽게 이해할 수 있습니다, 참고: https://jimmy-ai.tistory.com/32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# SVM 결과로 시각화(PCA 2차원 축소 후 결과 확인)\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# test 데이터셋 기준 시각화 진행\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "\n",
    "y_find = df_digits['number']\n",
    "y_find.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import category_scatter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터의 특징에 따라 어떤 모델이 어울릴지 생각해보는 판단능력이 미흡하다는 생각이 많이 들었습니다.피처의 개수나 클래스의 개수, 데이터의 활용 목적과 의미, 기술통계량들을 바탕으로 한 전체적인 분포 등을 고려해 보아야 합니다. 그를 통해 어떤 모델이 논리적으로 어울릴 것인가 예측해보는 연습을 해 보아야겠다고 생각했습니다. 분류 모델들의 알고리즘을 더 공부하여 좀 더 적절하게 모델들을 이용할 수 있도록 해야겠다고 생각했습니다. 예를 들어 MNIST 분류 모델의 경우 다중분류에 강한 랜덤포레스트, 로지스틱 회귀등을 먼저 생각해 볼 수 있는 것처럼, 데이터 성격과 모델의 특성을 잘 파악하고 있으면 분석을 더 잘 할 수 있을 것 같습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 와인 분류 모델에서 Logistic regression 알고리즘이 정확도가 매우 높아서 다른 부분을 건드리지 않았습니다. 로지스틱 회귀 분류에서는 L1, L2 규제를 조절하는 하이퍼파라미터 C를 적절히 설정함으로써 그 성능을 높일 수 있습니다. 적절한 하이퍼 파라미터를 설정하는 연습을 더 해 보고 싶습니다.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 와인분류 모델에서 오차 행렬을 통한 지표 외에 roc-auc 곡선도 활용해 보고 싶었습니다. 기회가 된다면 적절한 지표를 더 다양하게 써 보고 싶습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 암 진단 모델은 아쉬움이 많이 남는 모델이었습니다. 전체적으로 모델들의 정확도가 95%이하로 낮았기 때문입니다. 이는 정확한 판단을 요구하는 의료분야에는 적합하지 않다고 볼 수 있습니다. 모델의 성능이 낮은 이유로는 데이터 전처리 과정상의 문제라고 예측됩니다. 오버피팅을 방지하기 위해 상관계수가 낮은 피처를 삭제했는데 그 과정에서 데이터의 학습에 문제가 되는 부분이 생긴 것 같습니다. 피처 중 일부를 삭제하지 않고 수행했을 때 더 높은 정확성을 기대할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델의 하이퍼파라미터를 설정하는 데 어려움이 있었습니다. 옵티마이저의 활용을 더 잘 해야겠다고 생각합니다. 특히 SVM의 경우 커널 종류에 따라 하이퍼파라미터의 영향을 매우 많이 받는다는 것을 알 수 있었습니다. SGD도 경사하강법에 의해 계산해 나가는 방식이므로 하이퍼파라미터를 더 잘 설정해야 한다고 생각합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체적으로 아쉬움이 많이 남는 프로젝트였습니다. 데이터를 불러오고 처리하고, 기본적인 모델에 적용하는 수순이 자연스러워져야 어떤 모델을 고르고 하이퍼파라미터를 어떻게 설정할지에 더욱 신경을 쓸 수 있는 시간이 늘어납니다. 연습을 많이 해야겠다고 느꼈습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/datasets.html (데이터셋의 정보)  \n",
    "https://ratsgo.github.io/machine%20learning/2017/03/26/tree/ (의사결정나무)  \n",
    "https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline (맷플롯립 inline 이미지화)  \n",
    "https://rk1993.tistory.com/entry/%EB%AA%A8%EB%8D%B8-%EC%84%B1%EB%8A%A5-%ED%8F%89%EA%B0%80-%EC%A7%80%ED%91%9C-%ED%9A%8C%EA%B7%80-%EB%AA%A8%EB%8D%B8-%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8  \n",
    "https://dongsam-memo.tistory.com/24 (SVM 모델의 다중 분류)  \n",
    "https://mangkyu.tistory.com/62) (SGD 배치 사이즈)  \n",
    "https://stackoverflow.com/questions/67604304/total-no-of-iterations-reached-limit-in-scikit-learn (max_iter 워닝)  \n",
    "https://jimmy-ai.tistory.com/32 (svm 모델 시각화)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7936b404da2d1aec6a116f19bfb62db118b47fc993c612f13b3cacad2daeda5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
