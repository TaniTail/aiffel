{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be6392f",
   "metadata": {},
   "source": [
    "# Going Deeper 03 AI Lyrics Generator\n",
    "###### 온라인 코어 2기 박수경  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcbbd02",
   "metadata": {},
   "source": [
    "이번 과제에서는 가사 데이터셋을 학습해 새로운 가사를 작성해 주는 인공지능을 구성해 보기로 한다. 규칙이 먼저 생기고 그에 맞는 문법에 따르는 기계어와는 다르게 자연적으로 존재하는 사람의 언어를 자연어라고 한다.  자연어는 규칙에 따라 생겨나는 것이 아니며, 따라서 통계적으로 접근하는 것이 가장 좋은 방법으로 알려져 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4bdad",
   "metadata": {},
   "source": [
    "이번 과제에 사용하는 라이브러리들을 먼저 import 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a112f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import glob  #glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import re #정규표현식\n",
    "from sklearn.model_selection import train_test_split # 데이터셋 분리\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fddf42",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 준비 및 읽어오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff4d86",
   "metadata": {},
   "source": [
    "glob 모듈을 사용해서 파일을 읽어온다. glob 를 활용하여 모든 txt 파일을 읽어온 후, raw_corpus 리스트에 문장 단위로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d70ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['', '', '[Spoken Intro:]', 'You ever want something ', \"that you know you shouldn't have \", \"The more you know you shouldn't have it, \", 'The more you want it ', 'And then one day you get it, ', \"It's so good too \", \"But it's just like my girl \"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "txt_file_path = 'data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "raw_corpus = [] \n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담는다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() #read() : 파일 전체의 내용을 하나의 문자열로 읽어온다. , splitlines()  : 여러라인으로 구분되어 있는 문자열을 한라인씩 분리하여 리스트로 반환\n",
    "        raw_corpus.extend(raw) # extend() : 리스트함수로 추가적인 내용을 연장 한다.\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db96a5",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222b2dc",
   "metadata": {},
   "source": [
    "가사 데이터를 정제하는 함수 preprocess_sentence()를 정의하고 각 문장에 대해 적용한다.\n",
    "\n",
    "지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거한다. 일반적으로 가사의 한 문장은 그렇게 길지 않기 때문에 적당한 길이의 문장을 학습하게 하는 것이다. 과제에서 제시한 max 토큰의 개수는 15개로, maxlen =15 로 설정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bdd6bb",
   "metadata": {},
   "source": [
    "정규표현식에서 https://stackoverflow.com/questions/13566052/using-r-with-variables-in-re-sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16257a8",
   "metadata": {},
   "source": [
    "한 문장에서 띄어쓰기를 기준으로 잘라 토큰화를 한다고 했을 때, 다음과 같은 처리를 할 필요가 있다.  \n",
    "> 1. 모든 글자들을 소문자로 바꾸고, 양쪽 공백을 지우기\n",
    "> 2. 특수문자 양쪽에 공백을 넣기\n",
    "> 3. 여러개의 공백은 하나의 공백으로 바꾸기\n",
    "> 4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꾸기\n",
    "> 5. 양쪽 공백 지우기\n",
    "> 6. 문장 시작에는 <start>, 끝에는 <end>를 넣어 표시하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c07c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence에서 원하는 것만 남기기\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1 다 소문자로 만들기,strip :공백 지우기,\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 특수문자의 양쪽에 공백을 넣기 (\\1 : 첫번째로 매치된 것에 대해) \n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개의 공백은 하나의 공백으로 바꾼다.\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꾼다 (^: 여)\n",
    "    sentence = sentence.strip() # 공백을 지운다.\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 시작과 끝에 start,end 붙인다\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8657657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '[Spoken Intro:]', 'You ever want something ', \"that you know you shouldn't have \", \"The more you know you shouldn't have it, \", 'The more you want it ', 'And then one day you get it, ', \"It's so good too \"]\n"
     ]
    }
   ],
   "source": [
    "# raw_corpus 안에 어떤 결과가 담겼는지 확인한다.\n",
    "\n",
    "print(raw_corpus[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a41a7",
   "metadata": {},
   "source": [
    " raw_corpus 에서 실제로 학습에 쓰일 문장들(elements)만 선택해서 corpus 리스트에 담는다. 이 때 가사가 아닌 line들은 corpus에 담지 않기 위해 여러 조건문을 사용하여 corpus에 append 한다. \n",
    "\n",
    " 일단 앞서 확인한 [Spoken Intro:] 같은 경우에도 가사가 아니다. 대체로 chorus: , verse: 같이 곡의 구성상의 역할을 알려주는 line은 가사가 아니므로 제외하고 싶었다.\n",
    " 이런 line들의 경우 끝이 :], :), :, ], ) 등으로 끝나는데 )로 끝나는 경우는 가사에 속할 수도 있으므로 :], :), :, ] 로 끝나는 것을 제외하기로 결정했다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0872740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> you ever want something <end>',\n",
       " '<start> that you know you shouldn t have <end>',\n",
       " '<start> the more you know you shouldn t have it , <end>',\n",
       " '<start> the more you want it <end>',\n",
       " '<start> and then one day you get it , <end>',\n",
       " '<start> it s so good too <end>',\n",
       " '<start> but it s just like my girl <end>',\n",
       " '<start> when she s around me <end>',\n",
       " '<start> i just feel so good , so good <end>',\n",
       " '<start> but right now i just feel cold , so cold <end>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corpus = []\n",
    "\n",
    "# raw_corpus list에 저장된 문장들을 순서대로 반환하여 sentence에 저장\n",
    "for sentence in raw_corpus:\n",
    "    #제외할 문장의 특성 -> continue: 건너뛰기\n",
    "\n",
    "    if len(sentence) == 0: \n",
    "        continue\n",
    "    if sentence[-1] == \":\": \n",
    "        continue\n",
    "    if len(sentence) == 0: \n",
    "        continue\n",
    "    if sentence[-1] == \"]\": \n",
    "        continue\n",
    "\n",
    "    if len(sentence) == 1: \n",
    "        continue\n",
    "\n",
    "    if sentence[-2:] == \":]\": \n",
    "        continue\n",
    "    if sentence[-2] == \":)\": \n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 몇 개 확인한다.\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc97bd3",
   "metadata": {},
   "source": [
    "### 토큰화 (Tokenize)  \n",
    "텐서플로우의 Tokenizer와 pad_sequences를 사용한다.\n",
    "가사에 사용되는 단어장의 크기는 20000으로 설정했다. 시간은 더 걸릴 수 있지만 풍부한 단어가 확보되어 더 괜찮은 작사봇이 될 수 있겠다고 생각했기 때문이다. 단어장에 포함되지 못한 단어는 unknown으로 처리한다.  \n",
    "pad_sequence 의 패딩 처리방법은 default 가 'pre' 이다. 따라서 뒤에 패딩을 추가하기 위해 'post'를 옵션으로 준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c508338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    7  156 ...    0    0    0]\n",
      " [   2   17    7 ...    0    0    0]\n",
      " [   2    6   98 ...    0    0    0]\n",
      " ...\n",
      " [   2  310    1 ...    0    0    0]\n",
      " [   5   34   45 ... 1163  142    3]\n",
      " [   5   34   45 ... 1163  142    3]] <keras_preprocessing.text.Tokenizer object at 0x7f490ad9b100>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=18000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, \\\n",
    "        padding='post',maxlen=15)  # 길이가 짧은 문장은 뒤에서부터 패딩(post), 토큰의 최대길이: 15  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad43cde",
   "metadata": {},
   "source": [
    "tokenizer.index_word 로 토큰들의 인덱스와 해당 단어를 딕셔너리로 확인할 수 있다. 스무개 정도만 확인해 보도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffebb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n",
      "11 : it\n",
      "12 : me\n",
      "13 : my\n",
      "14 : in\n",
      "15 : t\n",
      "16 : s\n",
      "17 : that\n",
      "18 : on\n",
      "19 : of\n",
      "20 : your\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.index_word: 현재 계산된 단어의 인덱스와 인덱스에 해당하는 단어를 dictionary 형대로 반환 (Ex. {index: '~~', index: '~~', ...})\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 20: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6cecd",
   "metadata": {},
   "source": [
    "정제된 문장을 토큰화까지 마치고 데이터를 텐서로 만들었다. 이제는 사이킷런의 train_test_split()으로 데이터를 분리하려고 한다. train_test_split()을 사용하려면 X, y(target)으로 데이터가 분리되어 있어야 하므로 tensor를 src_input과 tgt_input으로 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9119ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_input = tensor[:, :-1]  \n",
    "tgt_input = tensor[:, 1:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527fc935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   7 156  62 201   3   0   0   0   0   0   0   0   0]\n",
      "[  7 156  62 201   3   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b979ff3",
   "metadata": {},
   "source": [
    "## Step 3. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd227bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = \\\n",
    "    train_test_split(src_input, tgt_input, \\\n",
    "        test_size=0.2, random_state=1004, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53c49460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139572, 14)\n",
      "(34894, 14)\n",
      "(139572, 14)\n",
      "(34894, 14)\n"
     ]
    }
   ],
   "source": [
    "#데이터가 잘 분리되었는지 확인\n",
    "print(enc_train.shape)\n",
    "print(enc_val.shape) \n",
    "print(dec_train.shape) \n",
    "print(dec_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab19b562",
   "metadata": {},
   "source": [
    "buffer_size, batch_size, epoch, iteration을 다시 공부하는 계기가 되었다.\n",
    "(https://losskatsu.github.io/machine-learning/epoch-batch/)\n",
    "\n",
    "- Batch Size : 1회 역전파에서 gradient를 모을 데이터의 개수  \n",
    "- Buffer Size : 전체 데이터의 개수  \n",
    "\n",
    "- VOCAB_SIZE : 단어들의 개수와 padding '0'까지 합쳐서 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51bc6d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174466\n",
      "512\n",
      "340\n",
      "18001\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input) # 전체 문장의 개수\n",
    "print(BUFFER_SIZE)\n",
    "BATCH_SIZE = 512 \n",
    "print(BATCH_SIZE)\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE \n",
    "print(steps_per_epoch)\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   # padding '0' 까지 합쳐서 +1\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40178386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((14,), (14,)), types: (tf.int32, tf.int32)>\n",
      "<ShuffleDataset shapes: ((14,), (14,)), types: (tf.int32, tf.int32)>\n",
      "<BatchDataset shapes: ((512, 14), (512, 14)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "print(dataset)\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "print(dataset)\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90326e68",
   "metadata": {},
   "source": [
    "## Step 4. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e764e6",
   "metadata": {},
   "source": [
    "모델을 구성한다. 자연어처리에 적절한 LSTM 을 사용하도록 한다. LSTM은 RNN에서 발전된 그것의 한 종류로 'cell state', 'gate'의 개념을 다시 정리할 수 있었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7026c7",
   "metadata": {},
   "source": [
    "hidden_size1, hidden_size2 을 다르게 설정해도 된다. 하지만 (1024, 1024)일 때 가장 성능이 좋았다.  \n",
    "시도해본 값 : (1024, 512), (2048, 1024), (512, 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aed9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, hidden_size_2): # hidden_size\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True) \n",
    "        self.dp1 = tf.keras.layers.Dropout(0.25)\n",
    "        self.dp2 = tf.keras.layers.Dropout(0.25)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size_2, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.dp1(out) #드랍아웃 층을 추가해보기도, 빼보기도 했다.\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.dp2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 1024\n",
    "hidden_size = 1024\n",
    "\n",
    "hidden_size_2 = 1024\n",
    "\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size, hidden_size_2) # tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bbadfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512, 14, 18001), dtype=float32, numpy=\n",
       "array([[[-2.66729534e-04, -1.36932911e-04, -4.14854694e-05, ...,\n",
       "          2.50847224e-04,  2.34649015e-05, -3.77349643e-04],\n",
       "        [-3.29417060e-04, -4.43459459e-04, -2.93988560e-04, ...,\n",
       "          1.48530657e-04, -1.57207905e-04, -4.24889266e-04],\n",
       "        [-2.40203444e-04, -6.64155523e-04, -5.10229846e-04, ...,\n",
       "         -2.65822222e-04, -5.02532639e-04, -1.30445609e-04],\n",
       "        ...,\n",
       "        [-7.63678749e-04, -1.79349550e-03, -1.35645701e-03, ...,\n",
       "          1.46776414e-03,  1.10552937e-04, -4.99990478e-04],\n",
       "        [-7.76390429e-04, -1.37492560e-03, -1.23248238e-03, ...,\n",
       "          1.43815612e-03,  2.19180329e-05, -5.22951537e-04],\n",
       "        [-8.68742063e-04, -9.88657470e-04, -1.08741503e-03, ...,\n",
       "          1.28382654e-03, -1.75155292e-04, -7.00070581e-04]],\n",
       "\n",
       "       [[-2.66729534e-04, -1.36932911e-04, -4.14854694e-05, ...,\n",
       "          2.50847224e-04,  2.34649015e-05, -3.77349643e-04],\n",
       "        [-5.74644306e-04, -2.51092744e-04,  2.02665586e-04, ...,\n",
       "          4.33496723e-04,  2.66817107e-04, -4.06354200e-04],\n",
       "        [-8.10198602e-04,  8.38971973e-05,  2.63788737e-04, ...,\n",
       "          9.32222756e-04,  6.49135502e-04, -5.41936141e-04],\n",
       "        ...,\n",
       "        [-1.95794436e-03,  4.15274233e-04, -3.66349210e-04, ...,\n",
       "         -1.68904662e-04, -2.21465342e-03, -7.76763598e-04],\n",
       "        [-2.05537654e-03,  4.13492526e-04, -3.14883393e-04, ...,\n",
       "         -2.25367156e-04, -2.55866605e-03, -7.17345625e-04],\n",
       "        [-2.13720882e-03,  4.00530582e-04, -2.54762068e-04, ...,\n",
       "         -2.76333682e-04, -2.87267356e-03, -6.39037229e-04]],\n",
       "\n",
       "       [[-2.66729534e-04, -1.36932911e-04, -4.14854694e-05, ...,\n",
       "          2.50847224e-04,  2.34649015e-05, -3.77349643e-04],\n",
       "        [-2.29957906e-04, -2.31890313e-04, -1.66017810e-04, ...,\n",
       "         -2.90629305e-05, -2.09605772e-04, -1.84861085e-04],\n",
       "        [-2.30908219e-04, -9.89925684e-05,  3.76158394e-04, ...,\n",
       "         -4.33710899e-04, -2.45305884e-04,  4.78028087e-05],\n",
       "        ...,\n",
       "        [-1.71489234e-03, -1.47764600e-04, -2.29005748e-03, ...,\n",
       "         -2.84146459e-04,  1.83473493e-03, -1.25915848e-03],\n",
       "        [-1.98245794e-03, -4.67954320e-04, -2.54689669e-03, ...,\n",
       "         -4.06544859e-05,  1.99189130e-03, -6.73067814e-04],\n",
       "        [-2.08203122e-03, -7.97625340e-04, -2.63376138e-03, ...,\n",
       "          9.33625633e-05,  1.83113129e-03, -4.09882457e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.66729534e-04, -1.36932911e-04, -4.14854694e-05, ...,\n",
       "          2.50847224e-04,  2.34649015e-05, -3.77349643e-04],\n",
       "        [-3.69258487e-04, -2.98746399e-05, -3.20296793e-04, ...,\n",
       "          4.06151958e-04,  4.15488845e-04, -5.72800636e-04],\n",
       "        [-2.93361256e-04, -1.42753837e-04, -7.41980912e-04, ...,\n",
       "          3.53041134e-04,  2.57281499e-04, -5.15339780e-04],\n",
       "        ...,\n",
       "        [-9.91448760e-04, -2.83622270e-04, -1.95375877e-03, ...,\n",
       "         -1.17049890e-03, -1.35321892e-03, -6.80666009e-04],\n",
       "        [-1.22006342e-03, -1.31217879e-04, -1.78064033e-03, ...,\n",
       "         -1.13385392e-03, -1.63196458e-03, -7.50370615e-04],\n",
       "        [-1.43881154e-03, -5.50166362e-07, -1.59072096e-03, ...,\n",
       "         -1.07047346e-03, -1.91800308e-03, -7.77859823e-04]],\n",
       "\n",
       "       [[-2.66729534e-04, -1.36932911e-04, -4.14854694e-05, ...,\n",
       "          2.50847224e-04,  2.34649015e-05, -3.77349643e-04],\n",
       "        [-2.29957906e-04, -2.31890313e-04, -1.66017810e-04, ...,\n",
       "         -2.90629305e-05, -2.09605772e-04, -1.84861085e-04],\n",
       "        [-7.64270197e-04,  1.71604261e-05, -1.12105336e-04, ...,\n",
       "         -4.51627653e-04, -6.19379280e-04, -2.39062851e-04],\n",
       "        ...,\n",
       "        [-2.26182095e-03,  5.18175773e-04, -3.34747165e-05, ...,\n",
       "         -3.51493363e-04, -2.48886319e-03,  3.86457163e-04],\n",
       "        [-2.37528235e-03,  4.93730768e-04, -5.50480909e-05, ...,\n",
       "         -3.53192649e-04, -2.70715007e-03,  2.72995618e-04],\n",
       "        [-2.47407798e-03,  4.62362310e-04, -6.10304160e-05, ...,\n",
       "         -3.57179437e-04, -2.92535289e-03,  1.88553953e-04]],\n",
       "\n",
       "       [[-2.66729534e-04, -1.36932911e-04, -4.14854694e-05, ...,\n",
       "          2.50847224e-04,  2.34649015e-05, -3.77349643e-04],\n",
       "        [-4.18764277e-04, -4.77593916e-04,  1.85747427e-04, ...,\n",
       "          4.70694504e-04, -5.84997497e-06, -3.40854051e-04],\n",
       "        [-2.57297826e-04, -4.43000958e-04, -1.21255733e-04, ...,\n",
       "          4.45673038e-04, -2.52986647e-04, -4.13345610e-04],\n",
       "        ...,\n",
       "        [-2.93403794e-03,  5.73499769e-04, -9.04872315e-04, ...,\n",
       "         -7.82576622e-04, -2.34130491e-03,  3.74209136e-04],\n",
       "        [-2.95765605e-03,  6.28423179e-04, -7.96758628e-04, ...,\n",
       "         -7.80640461e-04, -2.60532787e-03,  2.62676127e-04],\n",
       "        [-2.96962610e-03,  6.47362904e-04, -6.82316488e-04, ...,\n",
       "         -7.59848917e-04, -2.85316841e-03,  1.73105233e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러와서 모델에 넣어 본다.\n",
    "\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea6fc8c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  18433024  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  18451025  \n",
      "=================================================================\n",
      "Total params: 53,669,457\n",
      "Trainable params: 53,669,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델의 구조 확인.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81c90b",
   "metadata": {},
   "source": [
    "옵티마이저로 adam 을 사용한다. \n",
    "loss 로는 SparseCategoricalCrossentropy. 설정 파라미터 from_logits, reduction 을 잘 몰라서 찾아보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ee6f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, \\\n",
    "                                     beta_1=0.8, beta_2= 0.9,epsilon=1e-07, amsgrad=True)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 학습 데이터의 label이 정수일 경우 사용하는 손실함수\n",
    "    from_logits=True, # 기본값 False. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
    "    reduction='none'  # 기본값 SUM이다. 각자 나오는 값의 반환을 원할 때 None을 사용한다.\n",
    ")\n",
    "# 컴파일\n",
    "model.compile(loss=loss, optimizer=optimizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a13f27d",
   "metadata": {},
   "source": [
    "learning_rate를 기본값에서 0.005로 바꾸었을 때 전체적으로 가장 성능이 잘 나왔다.  \n",
    "(시도해본 값 : 0.001, 0.005, 0.003, 0.002,  0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d2d517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "273/273 [==============================] - 140s 503ms/step - loss: 3.7975 - val_loss: 3.3473\n",
      "Epoch 2/3\n",
      "273/273 [==============================] - 137s 502ms/step - loss: 3.2657 - val_loss: 3.1806\n",
      "Epoch 3/3\n",
      "273/273 [==============================] - 137s 502ms/step - loss: 3.1184 - val_loss: 3.0800\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(enc_train, dec_train, epochs=3, batch_size=BATCH_SIZE, validation_data = (enc_val, dec_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b53607b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epoch = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epoch, loss, 'c-', label='train_loss')\n",
    "plt.plot(epoch, val_loss, 'm--', label='val_loss')\n",
    "plt.title('Train Loss, Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219f769",
   "metadata": {},
   "source": [
    "loss를 그래프로 나타내었다. val_loss가 증가하기 시작하는 지점이 과대적합이 시작되는 지점이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e280ca6d",
   "metadata": {},
   "source": [
    "## Step 5. 가사 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe7680e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장생성 함수 정의\n",
    "#모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=15): \n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True:\n",
    "       \n",
    "        predict = model(test_tensor) \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d363554a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i m a little one <end> '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f75634c",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae55ec3",
   "metadata": {},
   "source": [
    "- 모델을 구성하고 model.build()나 model.fit()을 한번이라도 하지 않으면 model.summary()를 볼 수 없기 때문에 model(src_sample)로 한 번 넣어 본 것이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b444b9",
   "metadata": {},
   "source": [
    "- loss SparseCategoricalCrossentropy, from_logits, reduction 에 대해 한번 더 찾아보고 정리할 수 있었다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3c5ab",
   "metadata": {},
   "source": [
    "- keras subclassing 방법으로 모델을 만들 때.  \n",
    "\n",
    " ![](https://d3s0tskafalll9.cloudfront.net/media/images/E-12-4.max-800x600.png) \n",
    " \n",
    " 제시된 코드는  \n",
    " ```python  \n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    ```\n",
    "    \n",
    "   이다.  그런데 모델 안의 rnn1 레이어와 rnn2 레이어는 완전히 같은 층이어서 다르게 이름을 줄 필요가 있는지 의문이 들었다. 만약 층이 동일하다면 \\__ init\\__ 에서 LSTM 레이어를 하나만 설정하고 call 안에서 같은 층을 두 번 통과하게 하면 될 일이 아닌가하고 생각을 했다.  \n",
    "   그러나 학습된 데이터가 층을 통과하면 그 층이 결국 배운 건 '파라미터',즉 웨이트이다. 만일 다시 그 층을 통과하게 되면 기껏 처음 통과하며 배운 웨이트가 변하게 되어서 의미가 없어진다. 층을 통과하며 학습된 웨이트가 다르기 때문에 두 층은 다르게 설정해야 한다는 사실을 알았다. (freeze의 원리와도 동일한 이유)  \n",
    "   딥러닝 모델에 대해 조금 더 곰곰히 생각해 보는 기회가 되었다.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b6e27",
   "metadata": {},
   "source": [
    "- 모델의 하이퍼파라미터 뿐만이 아니라 words 의 개수를 조절했을 때도 확연한 차이가 있었다. 단어장의 크기를 24000, 20000, 18000개등 시도를 해 봤는데 18000개일 때 가장 성능이 좋았다. 나는 어휘가 풍부하면 더 성능이 좋을 거라고만 생각을 했는데 그게 아니었다. 물론 단어장의 크기가 크면 그에 맞는 모델의 하이퍼파라미터가 딱 있을 거지만, 내가 설정하기엔 아직 fine-tuning하는 것이 어려웠다.  \n",
    "\n",
    "- 드랍아웃 층의추가.  \n",
    "    TextGenerator(tf.keras.Model)의 구조를 짜면서 층 사이에 드랍아웃 층을 추가해 보기도 했고 위치를 옮겨보기도 했다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8bd4e",
   "metadata": {},
   "source": [
    "- 결과가 loss 2.2 밑으로 내려가지 못했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce6f11",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4571db",
   "metadata": {},
   "source": [
    "\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer (토크나이즈)  \n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences (문장에 패딩주기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b645675",
   "metadata": {},
   "source": [
    "- https://codetorial.net/tensorflow/natural_language_processing_in_tensorflow_01.html (tokenizer의 여러가지 사용법에 대해 찾아보고 토큰으로 인코딩하는 방법에 조금 더 익숙해질 수 있었다.)\n",
    "\n",
    "- https://stats.stackexchange.com/questions/265400/deep-learning-how-does-beta-1-and-beta-2-in-the-adam-optimizer-affect-its-lear  \n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam (아담의 베타값 설정)\n",
    "\n",
    "- https://hyunw.kim/blog/2017/11/01/Optimization.html (옵티마이저)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
